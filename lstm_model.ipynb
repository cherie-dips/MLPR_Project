{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb82ca02-dc94-4a8a-8086-b2ce2625e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7aa8b-ff0c-454b-bc08-5db403dccd46",
   "metadata": {},
   "source": [
    "#### Generating CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350e186f-f6ce-4c48-aeca-e7bcfc2604bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV file 'hydrogel_dataset.csv' generated with corrected timestamps.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Actual hydrogel degradation timepoints (in hours)\n",
    "actual_hours = [0, 24, 30, 48, 72, 95, 120, 168, 192, 216, 264]\n",
    "\n",
    "data = []\n",
    "global_well_id = 1\n",
    "\n",
    "for pH in [5, 6, 7, 8]:\n",
    "    for local_well in range(1, 49):  # 48 wells per pH\n",
    "        row = {\n",
    "            'Well': global_well_id,\n",
    "            'pH': pH\n",
    "        }\n",
    "        for i, hour in enumerate(actual_hours):\n",
    "            day_col = f'Day {i + 1}'  # Still name it Day 1 to Day 11\n",
    "            filename = f'cropped_{hour}hr_pH{pH}_W{local_well}.JPG'\n",
    "            row[day_col] = filename\n",
    "        data.append(row)\n",
    "        global_well_id += 1\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"hydrogel_dataset.csv\", index=False)\n",
    "print(\"✅ CSV file 'hydrogel_dataset.csv' generated with corrected timestamps.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edd687fd-e0d2-450b-bf6e-944ce93c9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hydrogel_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bdc85ae-faa2-4b25-84c6-3a84f80318df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Well</th>\n",
       "      <th>pH</th>\n",
       "      <th>Day 1</th>\n",
       "      <th>Day 2</th>\n",
       "      <th>Day 3</th>\n",
       "      <th>Day 4</th>\n",
       "      <th>Day 5</th>\n",
       "      <th>Day 6</th>\n",
       "      <th>Day 7</th>\n",
       "      <th>Day 8</th>\n",
       "      <th>Day 9</th>\n",
       "      <th>Day 10</th>\n",
       "      <th>Day 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>cropped_0hr_pH5_W1.JPG</td>\n",
       "      <td>cropped_24hr_pH5_W1.JPG</td>\n",
       "      <td>cropped_30hr_pH5_W1.JPG</td>\n",
       "      <td>cropped_48hr_pH5_W1.JPG</td>\n",
       "      <td>cropped_72hr_pH5_W1.JPG</td>\n",
       "      <td>cropped_95hr_pH5_W1.JPG</td>\n",
       "      <td>cropped_120hr_pH5_W1.JPG</td>\n",
       "      <td>cropped_168hr_pH5_W1.JPG</td>\n",
       "      <td>cropped_192hr_pH5_W1.JPG</td>\n",
       "      <td>cropped_216hr_pH5_W1.JPG</td>\n",
       "      <td>cropped_264hr_pH5_W1.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>cropped_0hr_pH5_W2.JPG</td>\n",
       "      <td>cropped_24hr_pH5_W2.JPG</td>\n",
       "      <td>cropped_30hr_pH5_W2.JPG</td>\n",
       "      <td>cropped_48hr_pH5_W2.JPG</td>\n",
       "      <td>cropped_72hr_pH5_W2.JPG</td>\n",
       "      <td>cropped_95hr_pH5_W2.JPG</td>\n",
       "      <td>cropped_120hr_pH5_W2.JPG</td>\n",
       "      <td>cropped_168hr_pH5_W2.JPG</td>\n",
       "      <td>cropped_192hr_pH5_W2.JPG</td>\n",
       "      <td>cropped_216hr_pH5_W2.JPG</td>\n",
       "      <td>cropped_264hr_pH5_W2.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>cropped_0hr_pH5_W3.JPG</td>\n",
       "      <td>cropped_24hr_pH5_W3.JPG</td>\n",
       "      <td>cropped_30hr_pH5_W3.JPG</td>\n",
       "      <td>cropped_48hr_pH5_W3.JPG</td>\n",
       "      <td>cropped_72hr_pH5_W3.JPG</td>\n",
       "      <td>cropped_95hr_pH5_W3.JPG</td>\n",
       "      <td>cropped_120hr_pH5_W3.JPG</td>\n",
       "      <td>cropped_168hr_pH5_W3.JPG</td>\n",
       "      <td>cropped_192hr_pH5_W3.JPG</td>\n",
       "      <td>cropped_216hr_pH5_W3.JPG</td>\n",
       "      <td>cropped_264hr_pH5_W3.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>cropped_0hr_pH5_W4.JPG</td>\n",
       "      <td>cropped_24hr_pH5_W4.JPG</td>\n",
       "      <td>cropped_30hr_pH5_W4.JPG</td>\n",
       "      <td>cropped_48hr_pH5_W4.JPG</td>\n",
       "      <td>cropped_72hr_pH5_W4.JPG</td>\n",
       "      <td>cropped_95hr_pH5_W4.JPG</td>\n",
       "      <td>cropped_120hr_pH5_W4.JPG</td>\n",
       "      <td>cropped_168hr_pH5_W4.JPG</td>\n",
       "      <td>cropped_192hr_pH5_W4.JPG</td>\n",
       "      <td>cropped_216hr_pH5_W4.JPG</td>\n",
       "      <td>cropped_264hr_pH5_W4.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>cropped_0hr_pH5_W5.JPG</td>\n",
       "      <td>cropped_24hr_pH5_W5.JPG</td>\n",
       "      <td>cropped_30hr_pH5_W5.JPG</td>\n",
       "      <td>cropped_48hr_pH5_W5.JPG</td>\n",
       "      <td>cropped_72hr_pH5_W5.JPG</td>\n",
       "      <td>cropped_95hr_pH5_W5.JPG</td>\n",
       "      <td>cropped_120hr_pH5_W5.JPG</td>\n",
       "      <td>cropped_168hr_pH5_W5.JPG</td>\n",
       "      <td>cropped_192hr_pH5_W5.JPG</td>\n",
       "      <td>cropped_216hr_pH5_W5.JPG</td>\n",
       "      <td>cropped_264hr_pH5_W5.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>188</td>\n",
       "      <td>8</td>\n",
       "      <td>cropped_0hr_pH8_W44.JPG</td>\n",
       "      <td>cropped_24hr_pH8_W44.JPG</td>\n",
       "      <td>cropped_30hr_pH8_W44.JPG</td>\n",
       "      <td>cropped_48hr_pH8_W44.JPG</td>\n",
       "      <td>cropped_72hr_pH8_W44.JPG</td>\n",
       "      <td>cropped_95hr_pH8_W44.JPG</td>\n",
       "      <td>cropped_120hr_pH8_W44.JPG</td>\n",
       "      <td>cropped_168hr_pH8_W44.JPG</td>\n",
       "      <td>cropped_192hr_pH8_W44.JPG</td>\n",
       "      <td>cropped_216hr_pH8_W44.JPG</td>\n",
       "      <td>cropped_264hr_pH8_W44.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>189</td>\n",
       "      <td>8</td>\n",
       "      <td>cropped_0hr_pH8_W45.JPG</td>\n",
       "      <td>cropped_24hr_pH8_W45.JPG</td>\n",
       "      <td>cropped_30hr_pH8_W45.JPG</td>\n",
       "      <td>cropped_48hr_pH8_W45.JPG</td>\n",
       "      <td>cropped_72hr_pH8_W45.JPG</td>\n",
       "      <td>cropped_95hr_pH8_W45.JPG</td>\n",
       "      <td>cropped_120hr_pH8_W45.JPG</td>\n",
       "      <td>cropped_168hr_pH8_W45.JPG</td>\n",
       "      <td>cropped_192hr_pH8_W45.JPG</td>\n",
       "      <td>cropped_216hr_pH8_W45.JPG</td>\n",
       "      <td>cropped_264hr_pH8_W45.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>190</td>\n",
       "      <td>8</td>\n",
       "      <td>cropped_0hr_pH8_W46.JPG</td>\n",
       "      <td>cropped_24hr_pH8_W46.JPG</td>\n",
       "      <td>cropped_30hr_pH8_W46.JPG</td>\n",
       "      <td>cropped_48hr_pH8_W46.JPG</td>\n",
       "      <td>cropped_72hr_pH8_W46.JPG</td>\n",
       "      <td>cropped_95hr_pH8_W46.JPG</td>\n",
       "      <td>cropped_120hr_pH8_W46.JPG</td>\n",
       "      <td>cropped_168hr_pH8_W46.JPG</td>\n",
       "      <td>cropped_192hr_pH8_W46.JPG</td>\n",
       "      <td>cropped_216hr_pH8_W46.JPG</td>\n",
       "      <td>cropped_264hr_pH8_W46.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>191</td>\n",
       "      <td>8</td>\n",
       "      <td>cropped_0hr_pH8_W47.JPG</td>\n",
       "      <td>cropped_24hr_pH8_W47.JPG</td>\n",
       "      <td>cropped_30hr_pH8_W47.JPG</td>\n",
       "      <td>cropped_48hr_pH8_W47.JPG</td>\n",
       "      <td>cropped_72hr_pH8_W47.JPG</td>\n",
       "      <td>cropped_95hr_pH8_W47.JPG</td>\n",
       "      <td>cropped_120hr_pH8_W47.JPG</td>\n",
       "      <td>cropped_168hr_pH8_W47.JPG</td>\n",
       "      <td>cropped_192hr_pH8_W47.JPG</td>\n",
       "      <td>cropped_216hr_pH8_W47.JPG</td>\n",
       "      <td>cropped_264hr_pH8_W47.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>192</td>\n",
       "      <td>8</td>\n",
       "      <td>cropped_0hr_pH8_W48.JPG</td>\n",
       "      <td>cropped_24hr_pH8_W48.JPG</td>\n",
       "      <td>cropped_30hr_pH8_W48.JPG</td>\n",
       "      <td>cropped_48hr_pH8_W48.JPG</td>\n",
       "      <td>cropped_72hr_pH8_W48.JPG</td>\n",
       "      <td>cropped_95hr_pH8_W48.JPG</td>\n",
       "      <td>cropped_120hr_pH8_W48.JPG</td>\n",
       "      <td>cropped_168hr_pH8_W48.JPG</td>\n",
       "      <td>cropped_192hr_pH8_W48.JPG</td>\n",
       "      <td>cropped_216hr_pH8_W48.JPG</td>\n",
       "      <td>cropped_264hr_pH8_W48.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Well  pH                    Day 1                     Day 2  \\\n",
       "0       1   5   cropped_0hr_pH5_W1.JPG   cropped_24hr_pH5_W1.JPG   \n",
       "1       2   5   cropped_0hr_pH5_W2.JPG   cropped_24hr_pH5_W2.JPG   \n",
       "2       3   5   cropped_0hr_pH5_W3.JPG   cropped_24hr_pH5_W3.JPG   \n",
       "3       4   5   cropped_0hr_pH5_W4.JPG   cropped_24hr_pH5_W4.JPG   \n",
       "4       5   5   cropped_0hr_pH5_W5.JPG   cropped_24hr_pH5_W5.JPG   \n",
       "..    ...  ..                      ...                       ...   \n",
       "187   188   8  cropped_0hr_pH8_W44.JPG  cropped_24hr_pH8_W44.JPG   \n",
       "188   189   8  cropped_0hr_pH8_W45.JPG  cropped_24hr_pH8_W45.JPG   \n",
       "189   190   8  cropped_0hr_pH8_W46.JPG  cropped_24hr_pH8_W46.JPG   \n",
       "190   191   8  cropped_0hr_pH8_W47.JPG  cropped_24hr_pH8_W47.JPG   \n",
       "191   192   8  cropped_0hr_pH8_W48.JPG  cropped_24hr_pH8_W48.JPG   \n",
       "\n",
       "                        Day 3                     Day 4  \\\n",
       "0     cropped_30hr_pH5_W1.JPG   cropped_48hr_pH5_W1.JPG   \n",
       "1     cropped_30hr_pH5_W2.JPG   cropped_48hr_pH5_W2.JPG   \n",
       "2     cropped_30hr_pH5_W3.JPG   cropped_48hr_pH5_W3.JPG   \n",
       "3     cropped_30hr_pH5_W4.JPG   cropped_48hr_pH5_W4.JPG   \n",
       "4     cropped_30hr_pH5_W5.JPG   cropped_48hr_pH5_W5.JPG   \n",
       "..                        ...                       ...   \n",
       "187  cropped_30hr_pH8_W44.JPG  cropped_48hr_pH8_W44.JPG   \n",
       "188  cropped_30hr_pH8_W45.JPG  cropped_48hr_pH8_W45.JPG   \n",
       "189  cropped_30hr_pH8_W46.JPG  cropped_48hr_pH8_W46.JPG   \n",
       "190  cropped_30hr_pH8_W47.JPG  cropped_48hr_pH8_W47.JPG   \n",
       "191  cropped_30hr_pH8_W48.JPG  cropped_48hr_pH8_W48.JPG   \n",
       "\n",
       "                        Day 5                     Day 6  \\\n",
       "0     cropped_72hr_pH5_W1.JPG   cropped_95hr_pH5_W1.JPG   \n",
       "1     cropped_72hr_pH5_W2.JPG   cropped_95hr_pH5_W2.JPG   \n",
       "2     cropped_72hr_pH5_W3.JPG   cropped_95hr_pH5_W3.JPG   \n",
       "3     cropped_72hr_pH5_W4.JPG   cropped_95hr_pH5_W4.JPG   \n",
       "4     cropped_72hr_pH5_W5.JPG   cropped_95hr_pH5_W5.JPG   \n",
       "..                        ...                       ...   \n",
       "187  cropped_72hr_pH8_W44.JPG  cropped_95hr_pH8_W44.JPG   \n",
       "188  cropped_72hr_pH8_W45.JPG  cropped_95hr_pH8_W45.JPG   \n",
       "189  cropped_72hr_pH8_W46.JPG  cropped_95hr_pH8_W46.JPG   \n",
       "190  cropped_72hr_pH8_W47.JPG  cropped_95hr_pH8_W47.JPG   \n",
       "191  cropped_72hr_pH8_W48.JPG  cropped_95hr_pH8_W48.JPG   \n",
       "\n",
       "                         Day 7                      Day 8  \\\n",
       "0     cropped_120hr_pH5_W1.JPG   cropped_168hr_pH5_W1.JPG   \n",
       "1     cropped_120hr_pH5_W2.JPG   cropped_168hr_pH5_W2.JPG   \n",
       "2     cropped_120hr_pH5_W3.JPG   cropped_168hr_pH5_W3.JPG   \n",
       "3     cropped_120hr_pH5_W4.JPG   cropped_168hr_pH5_W4.JPG   \n",
       "4     cropped_120hr_pH5_W5.JPG   cropped_168hr_pH5_W5.JPG   \n",
       "..                         ...                        ...   \n",
       "187  cropped_120hr_pH8_W44.JPG  cropped_168hr_pH8_W44.JPG   \n",
       "188  cropped_120hr_pH8_W45.JPG  cropped_168hr_pH8_W45.JPG   \n",
       "189  cropped_120hr_pH8_W46.JPG  cropped_168hr_pH8_W46.JPG   \n",
       "190  cropped_120hr_pH8_W47.JPG  cropped_168hr_pH8_W47.JPG   \n",
       "191  cropped_120hr_pH8_W48.JPG  cropped_168hr_pH8_W48.JPG   \n",
       "\n",
       "                         Day 9                     Day 10  \\\n",
       "0     cropped_192hr_pH5_W1.JPG   cropped_216hr_pH5_W1.JPG   \n",
       "1     cropped_192hr_pH5_W2.JPG   cropped_216hr_pH5_W2.JPG   \n",
       "2     cropped_192hr_pH5_W3.JPG   cropped_216hr_pH5_W3.JPG   \n",
       "3     cropped_192hr_pH5_W4.JPG   cropped_216hr_pH5_W4.JPG   \n",
       "4     cropped_192hr_pH5_W5.JPG   cropped_216hr_pH5_W5.JPG   \n",
       "..                         ...                        ...   \n",
       "187  cropped_192hr_pH8_W44.JPG  cropped_216hr_pH8_W44.JPG   \n",
       "188  cropped_192hr_pH8_W45.JPG  cropped_216hr_pH8_W45.JPG   \n",
       "189  cropped_192hr_pH8_W46.JPG  cropped_216hr_pH8_W46.JPG   \n",
       "190  cropped_192hr_pH8_W47.JPG  cropped_216hr_pH8_W47.JPG   \n",
       "191  cropped_192hr_pH8_W48.JPG  cropped_216hr_pH8_W48.JPG   \n",
       "\n",
       "                        Day 11  \n",
       "0     cropped_264hr_pH5_W1.JPG  \n",
       "1     cropped_264hr_pH5_W2.JPG  \n",
       "2     cropped_264hr_pH5_W3.JPG  \n",
       "3     cropped_264hr_pH5_W4.JPG  \n",
       "4     cropped_264hr_pH5_W5.JPG  \n",
       "..                         ...  \n",
       "187  cropped_264hr_pH8_W44.JPG  \n",
       "188  cropped_264hr_pH8_W45.JPG  \n",
       "189  cropped_264hr_pH8_W46.JPG  \n",
       "190  cropped_264hr_pH8_W47.JPG  \n",
       "191  cropped_264hr_pH8_W48.JPG  \n",
       "\n",
       "[192 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80a3e46-3b58-4bda-9f9f-fd4e0a009bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3f53ce-65bc-4c16-a693-c5f178fa72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0f01e6-be7a-4b57-8bd0-7bab1d38c0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 192/192 [00:18<00:00, 10.32it/s]\n"
     ]
    }
   ],
   "source": [
    "image_sequences = []\n",
    "labels = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    pH = int(row['pH'])\n",
    "    well_sequence = []\n",
    "\n",
    "    for day in row[2:]:  # skip well_num and pH\n",
    "        found = False\n",
    "        for time_folder in os.listdir('Final_Data'):\n",
    "            time_path = os.path.join('Final_Data', time_folder)\n",
    "            if not os.path.isdir(time_path): continue\n",
    "            for pH_folder in os.listdir(time_path):\n",
    "                pH_path = os.path.join(time_path, pH_folder)\n",
    "                if not os.path.isdir(pH_path): continue\n",
    "                img_path = os.path.join(pH_path, day)\n",
    "                if os.path.exists(img_path):\n",
    "                    img = cv2.imread(img_path)\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = transform(img)\n",
    "                    well_sequence.append(img)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "\n",
    "    if len(well_sequence) == 11:\n",
    "        image_sequences.append(torch.stack(well_sequence))  # (11, 3, 224, 224)\n",
    "        labels.append(pH - 5)  # Convert pH 5-8 to class 0-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5faf63f0-78ff-44c7-aea1-f7da53452a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HydrogelDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]\n",
    "\n",
    "dataset = HydrogelDataset(image_sequences, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8be880a-b647-49b2-96ec-d37a7d19cf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tishabhavsar/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/tishabhavsar/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # remove last FC layer\n",
    "resnet.eval()\n",
    "\n",
    "cnn_lstm = nn.Sequential(\n",
    "    nn.LSTM(input_size=512, hidden_size=256, num_layers=1, batch_first=True),\n",
    "    nn.Linear(256, 4)  # 4 pH classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a6c5364-cd27-4bcc-92b4-f09bdc07c898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:10<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:11<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.3235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.1373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.1892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.6141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.5364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:10<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.7871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:10<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.4087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = resnet.to(device)\n",
    "cnn_lstm = cnn_lstm.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_lstm.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(12):\n",
    "    for seqs, lbls in tqdm(dataloader):\n",
    "        batch_size = seqs.shape[0]\n",
    "        seqs = seqs.to(device)  # (B, 11, 3, 224, 224)\n",
    "        lbls = lbls.to(device)\n",
    "\n",
    "        features = []\n",
    "        for t in range(seqs.shape[1]):\n",
    "            img_batch = seqs[:, t, :, :, :]  # (B, 3, 224, 224)\n",
    "            with torch.no_grad():\n",
    "                feat = resnet(img_batch)  # (B, 512)\n",
    "            features.append(feat)\n",
    "\n",
    "        features = torch.stack(features, dim=1)  # (B, 11, 512)\n",
    "\n",
    "        outputs, _ = cnn_lstm[0](features)  # LSTM\n",
    "        final_out = outputs[:, -1, :]  # last timestep\n",
    "        preds = cnn_lstm[1](final_out)  # FC Layer\n",
    "\n",
    "        loss = criterion(preds, lbls)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de48755-727c-4b2d-99d3-4322910601de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_lstm.eval()\n",
    "resnet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9723cc30-14ed-4b24-83b0-ca3d00915149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test Accuracy: 92.50%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seqs, lbls in dataloader:  # replace with test_dataloader if you have one\n",
    "        seqs = seqs.to(device)\n",
    "        lbls = lbls.to(device)\n",
    "\n",
    "        features = []\n",
    "        for t in range(seqs.shape[1]):\n",
    "            img_batch = seqs[:, t, :, :, :]\n",
    "            feat = resnet(img_batch)\n",
    "            features.append(feat)\n",
    "\n",
    "        features = torch.stack(features, dim=1)  # (B, 11, 512)\n",
    "\n",
    "        outputs, _ = cnn_lstm[0](features)\n",
    "        final_out = outputs[:, -1, :]\n",
    "        preds = cnn_lstm[1](final_out)\n",
    "\n",
    "        _, predicted = torch.max(preds.data, 1)\n",
    "        total += lbls.size(0)\n",
    "        correct += (predicted == lbls).sum().item()\n",
    "\n",
    "print(f\"✅ Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb9c1c6-51eb-452e-9baa-14189e91256b",
   "metadata": {},
   "source": [
    "### Time Stamp Prediction "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
